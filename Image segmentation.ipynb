{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation and Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of contours found=4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# lets load a simple image with 3 black squares\n",
    "\n",
    "image = cv2.imread('.\\shape.jpg')\n",
    "cv2.imshow('input image',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Find Canny edges\n",
    "edged = cv2.Canny(gray,30,200)\n",
    "cv2.imshow('canny edges',edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Finding Contours\n",
    "# use a copy of your image e.g edged.copy(),since findContours alters the image\n",
    "\n",
    "_,contours,hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('canny edges after contouring',edged)\n",
    "cv2.waitKey(0)\n",
    "print(\"number of contours found=\"+ str(len(contours)))\n",
    "\n",
    "# draw all contours \n",
    "# use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image,contours,-1,(0,255,0),3)\n",
    "\n",
    "cv2.imshow('contours',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.CHAIN_APPROX_NONE stores all the boundary points\n",
    "# cv2.CHAIN_APPROX_SIMPLE provides just the start and end points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of contours found=4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "image=cv2.imread('.\\shape.jpg')\n",
    "cv2.imshow('0 - original image',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Create a black image with ame dimensions as our loaded image\n",
    "blank_image = np.zeros((image.shape[0],image.shape[1],3))\n",
    "\n",
    "# Create a copy of our original image\n",
    "original_image =image\n",
    "\n",
    "#Grayscale our image\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find canny edges\n",
    "edged = cv2.Canny(gray,50,200)\n",
    "cv2.imshow('1- canny edges',edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# find contours and print how many were found\n",
    "_,contours,hierarchy = cv2.findContours(edged.copy(),\n",
    "                                        cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "print(\"number of contours found=\"+ str(len(contours)))\n",
    "\n",
    "#DRAW all contours\n",
    "cv2.drawContours(blank_image,contours,-1,(0,255,0),3)\n",
    "cv2.imshow('2-all contours over blank image',blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# draw all contours over blank image\n",
    "cv2.drawContours(image,contours,-1,(0,255,0),3)\n",
    "cv2.imshow('3-all contours ',image)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sorting by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contours areas before sorting [17775.0, 19943.0, 33147.5, 9490.5]\n",
      "contours areas after sorting [33147.5, 19943.0, 17775.0, 9490.5]\n"
     ]
    }
   ],
   "source": [
    "# function we'll use to display contour area\n",
    "\n",
    "def get_contour_areas(contours):\n",
    "    #returns the areas of all contours as list\n",
    "    all_areas=[]\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "#load the image\n",
    "image = cv2.imread('.\\shape.jpg')\n",
    "original_image = image\n",
    "\n",
    "# lets print the areas of the contours before sorting\n",
    "print(\"contours areas before sorting\", get_contour_areas(contours))\n",
    "\n",
    "# sort contours large to small\n",
    "sorted_contours = sorted(contours,key=cv2.contourArea,reverse=True)\n",
    "# sorted_contours = sorted(contours,key=cv2.contoursArea,reverse=True) [:3]\n",
    "\n",
    "print(\"contours areas after sorting\",get_contour_areas(sorted_contours))\n",
    "\n",
    "# Iterate over our  contours and draw one at a time\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(original_image,[c],-1,(255,0,0),3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Contours by area',original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions we'll use for sorting by  position\n",
    "\n",
    "\n",
    "def x_cord_contour(contours):\n",
    "    #returns the x cordinate for the contour centroid\n",
    "    if cv2.contourArea(contours) >10:\n",
    "        M=cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    \n",
    "def label_Contour_center(image,c,i):\n",
    "    # places a red circle on the centers of contours\n",
    "    M=cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "    # draw the contour number on the image\n",
    "    cv2.circle(image,(cx,cy),10,(0,0,255),-1)\n",
    "    return image\n",
    "\n",
    "# load the image\n",
    "iamge = cv2.imread('.\\shape.jpg')\n",
    "original_image = image.copy()\n",
    "\n",
    "# compute center of mass or centroids and draw them on our image\n",
    "\n",
    "for(i,c) in enumerate(contours):\n",
    "    orig = label_Contour_center(image,c,i)\n",
    "    \n",
    "cv2.imshow(\"4 - contours center\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# sort by left to right using our X_cord_Contour function\n",
    "contours_left_to_right = sorted(contours,key=x_cord_contour,reverse=False)\n",
    "\n",
    "# labeling contours left to right\n",
    "\n",
    "for (i,c) in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(original_image,[c],-1,(0,0,255),3)\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    cv2.putText(original_image,str(i+1),(cx,cy),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.imshow('6 - left to right contour', original_image)\n",
    "    cv2.waitKey(0)\n",
    "    (x,y,w,h)=cv2.boundingRect(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('./house.png')\n",
    "orig_image = image.copy()\n",
    "cv2.imshow('original image',orig_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Grayscale and binarize\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "# find contours\n",
    "_,contours,hierarchy = cv2.findContours(thresh.copy(),cv2.RETR_LIST,\n",
    "                                      cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Iterate through each contour and compute the bounding rectangle\n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    cv2.imshow('bounding rectangle',orig_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#iterate through each contour and compute the approx contour\n",
    "\n",
    "for c in contours:\n",
    "    #calculate accuarcy as a percent of the contour perimeter\n",
    "    accuracy = 0.01 * cv2.arcLength(c,True)\n",
    "    approx = cv2.approxPolyDP(c,accuracy,True)\n",
    "    cv2.drawContours(image,[approx],0,(0,255,0),2)\n",
    "    cv2.imshow('approx ploy DP',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching contour shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2452531901514008\n",
      "1.3476111233699948\n",
      "0.09783837174596288\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# load the refernce image\n",
    "template = cv2.imread('./shapes1.png',0)\n",
    "#template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('template',template)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# load the imaghe which images we are trying to match\n",
    "target =cv2.imread('./shape1_test.png')\n",
    "target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold both images first before using cv2.findContours\n",
    "ret,thresh1 = cv2.threshold(template,127,255,0)\n",
    "ret,thresh2 = cv2.threshold(target_gray,127,255,0)\n",
    "\n",
    "# find contours in template\n",
    "_,contours,hierarchy = cv2.findContours(thresh1,cv2.RETR_CCOMP,\n",
    "                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# we need to sort the contours by area so we can remove thelargest contour which is\n",
    "# is the image outline\n",
    "\n",
    "sorted_contours = sorted(contours,key=cv2.contourArea,reverse=True)\n",
    "\n",
    "# we extract the second largest contour which will be our template contour \n",
    "template_contour = contours[1]\n",
    "\n",
    "#extract contours from second target image\n",
    "_,contours,hierarchy = cv2.findContours(thresh2,cv2.RETR_CCOMP,\n",
    "                                        cv2.CHAIN_APPROX_SIMPLE)\n",
    "for c in contours:\n",
    "    #Iterate through each contour in the target image and use cv2.matchshapes to \n",
    "    #compare contour shapes\n",
    "    match =cv2.matchShapes(template_contour,c,2,0.0)\n",
    "    print (match)\n",
    "    # if the match value is less than 0.15 we \n",
    "    if match < 0.15:\n",
    "        closest_contour = c\n",
    "        break\n",
    "    else:\n",
    "        closest_contour = []\n",
    "        \n",
    "cv2.drawContours(target,[closest_contour],-1,(0,255,0),3)\n",
    "cv2.imshow('output',target)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "image = cv2.imread('./sudoku.png')\n",
    "resized = imutils.resize(image,width=600)\n",
    "\n",
    "# grayscale and canny edges extracted \n",
    "gray = cv2.cvtColor(resized,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,100,170,apertureSize = 3)\n",
    "\n",
    "#run houghlines using a rho accuracy of 1 pixel\n",
    "#theta accuracy of np.pi / 180 which is 1 degree\n",
    "#our line threshold is set to 240(number of points on line)\n",
    "\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180,200)\n",
    "\n",
    "# we iterate through each line and convert it to the format required by cv.lines \n",
    "# (i.e requiring end points)\n",
    "for line in lines:\n",
    "    rho,theta =line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(resized, (x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "#cv2.imwrite('houghlines3.jpg',img)\n",
    "        \n",
    "    \n",
    "cv2.imshow('Hough lines', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Hough lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread('./sudoku.jpg')\n",
    "resized = imutils.resize(image,width=500)\n",
    "image=resized\n",
    "# grayscale and canny edges extracted \n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,100,170,apertureSize = 3)\n",
    "\n",
    "# Again we use the same rho and theta accuracies \n",
    "# however we specific a minimum vote (pts along line) of 100\n",
    "# and min line length of 5 pixels and max gap between lines of 10 pixels\n",
    "\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi / 180 , 150 ,5,10)\n",
    "#print(lines.shape)\n",
    "\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(image,(x1,y1),(x2,y2),(0,255,0),3)\n",
    "    \n",
    "cv2.imshow('Probabilistic Hough lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# circle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread('./bottlecap.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 10)\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (255, 0, 0), 2)\n",
    "      \n",
    "    # draw the center of the circle\n",
    "    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    "\n",
    "cv2.imshow('detected circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blob detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./sunflower.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "# set up the detector with default parameters.\n",
    "detector = cv2.SimpleBlobDetector_create()\n",
    "\n",
    "#detect blobs\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# draw detected blobs as red circles.\n",
    "#cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle\n",
    "#corresponds to the size of blob\n",
    "\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image,keypoints,blank,(0,255,255),cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imshow('blobs',blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
