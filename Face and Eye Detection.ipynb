{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face and Eye Detection using HAAR Cascade Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# we point opencv's cascadeclassifier function to where our \\\n",
    "# classifier(xmlfile format) is stored\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('C:/Users/winuser/Anaconda3/pkgs/libopencv-3.4.1-h875b8b8_3/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "#load the image then convert in grayscale\n",
    "image = cv2.imread('images/trump.jpg')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# our classifier returns the roi of the detected face as a tuple\n",
    "# it stores the top left coordinate and the bottom right coordinates\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "# when no face detected , face_Classifier returns and empty tuple\n",
    "\n",
    "if faces is ():\n",
    "    print(\"no faces found\")\n",
    "\n",
    "# we iterate through our faces array and draw a rectangle over each face in faces\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow('face detection',image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets combine face and eye detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "face_cascade = cv2.CascadeClassifier('C:/Users/winuser/Anaconda3/pkgs/libopencv-3.4.1-h875b8b8_3/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('C:/Users/winuser/Anaconda3/pkgs/libopencv-3.4.1-h875b8b8_3/Library/etc/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv.imread('images/eyes.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "cv.imshow('img',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\highgui\\src\\window.cpp:356: error: (-215) size.width>0 && size.height>0 in function cv::imshow\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-d0ad3764434b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"our face extractor\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\highgui\\src\\window.cpp:356: error: (-215) size.width>0 && size.height>0 in function cv::imshow\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "face_cascade = cv2.CascadeClassifier('C:/Users/winuser/Anaconda3/pkgs/libopencv-3.4.1-h875b8b8_3/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('C:/Users/winuser/Anaconda3/pkgs/libopencv-3.4.1-h875b8b8_3/Library/etc/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "def face_detector(img,size = 0.5):\n",
    "    #convert image to grayscale\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img\n",
    "    for (x,y,w,h) in faces:\n",
    "        x= x- 50\n",
    "        w = w + 50\n",
    "        y = y - 50\n",
    "        h= h + 50\n",
    "        cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    roi_color = cv2.flip(roi_color,1)\n",
    "    return roi_color\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow(\"our face extractor\",face_detector(frame))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('C:/Users/winuser/Anaconda3/pkgs/libopencv-3.4.1-h875b8b8_3/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('C:/Users/winuser/Anaconda3/pkgs/libopencv-3.4.1-h875b8b8_3/Library/etc/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning cascade classifier\n",
    "\n",
    "our_classifier.detectMultiScale(input image,Scale Factor , Min Neighbors)\n",
    "\n",
    "Scale Factor specifies how much we reduce thwe image size each time we scale Eg. in face detection we typically use 1.3. this mjeans that we reduce the iamge byh 30% each time its scaled.smaller values like 1.05 will take longer to compute, but will increase the rate of detection.\n",
    "\n",
    "Min Neighbors Specifies the number of neighbors each potential windowshould have in order to consider it is a positive detection.typically set btwn 3-6. it acts as sensitivity, setting low values will sometimes detect mutiples faces over a\n",
    "a single face.high values will ensure less false positives, but you may miss some faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
